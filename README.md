Title : DR. CROP

Usage : 
      Go to 34.100.167.221:5000 on your browser

PROJECT THEME:   AGRO-TECH

DESCRIPTION:
                 The main aim of our project is to create aawareness among the farmers about the potential yield of the crop and detect the pathogens in advance and advise them accordingly

PROBLEM STATEMENT:
            The problem at hand is the lack of access to reliable and timely information about crop-specific inputs, practices, and technologies that can optimize yield, reduce costs, and improve sustainability. The challenge is to build an effective recommendation engine that leverages agricultural data, machine learning algorithms, and user-centric design to deliver accurate, context-aware, and actionable recommendations to farmers while addressing data quality, scalability, and user issues adoption.

SOLUTION:
          Our solution, Dr Crop is an agro-tech application, that aims to develop a recommendation engine to provide personalized and data-driven agricultural recommendations to farmers in India. Use various machine learning algorithms and google cloud products to accurately forecast crop yields and suggest efficient and sustainable methods for producing fertilizers, such as using renewable resources, reducing energy consumption, minimizing waste, and optimizing nutrient content along with these we also help in early detection and diagnosis of plant diseases

FEATURES:
   Our application is providing three different functions:
1.	Crop prediction:
            Yield forecasting: The objective is to develop predictive models or tools that can accurately forecast crop yields, taking into account various factors such as weather conditions, soil fertility, crop growth stage, and management practices. This can assist farmers in making informed decisions about harvesting, storage, and marketing
            Resource allocation and management: The objective may be to optimize resource allocation and management, such as water, fertilizer, and labour, based on crop prediction, to improve resource use efficiency and reduce production costs.
2.	Fertilizer Productions:
Fertilizer allocation can be optimized based on soil test results and crop needs. Water allocation can be optimized based on the predicted demand of crops in different areas and seasons using various datasets and machine learning algorithms.
Environmental impact assessment: The objective is to evaluate the environmental impact of fertilizer production processes, including greenhouse gas emissions, water usage, and waste generation, and identify strategies for mitigating the negative impacts.
Quality control and nutrient optimization: The objective may be to develop techniques for quality control and nutrient optimization in fertilizer production, ensuring that the produced fertilizers meet regulatory standards and crop nutrient requirements.
3.	Plant Disease Prediction:
The objective may be to develop methods for predicting plant diseases, including those caused by pests and pathogens. The objective may be to develop techniques for predicting plant disease outbreaks in agricultural fields and identify strategies for mitigating the negative impacts of these outbreaks.
Precision Farming: we integrate plant disease prediction into precision agriculture practices, such as variable rate application of pesticides or fungicides, to optimize resource utilization and reduce the environmental impact of disease management practices.
TECHNOLOGY STACK:
Front End:
•	HTML : HTML stands for HyperText Markup Language. It is used to design web pages using the markup language. HTML is the combination of Hypertext and Markup language. Hypertext defines the link between the web pages and markup language defines the text document within the tag that define the structure of web pages. HTML is used to create the structure of web pages that are displayed on the World Wide Web (www). It contains Tags and Attributes that are used to design the web pages. Also, we can link multiple pages using Hyperlinks.
"Hypertext" refers to links that connect web pages to one another, either within a single website or between websites. Links are a fundamental aspect of the Web. By uploading content to the Internet and linking it to pages created by other people, you become an active participant in the World Wide Web.
An HTML element is set off from other text in a document by "tags", which consist of the element name surrounded by "<" and ">". The name of an element inside a tag is case insensitive. That is, it can be written in uppercase, lowercase, or a mixture. For example, the <title> tag can be written as <Title>, <TITLE>, or in any other way. However, the convention and recommended practice is to write tags in lowercase.
•	CSS : CSS is used to control the style of a web document in a simple and easy way.
CSS is the acronym for "Cascading Style Sheet". This tutorial covers both the versions CSS1,CSS2 and CSS3, and gives a complete understanding of CSS, starting from its basics to advanced concepts.
CSS handles the look and feel part of a web page. Using CSS, you can control the color of the text, the style of fonts, the spacing between paragraphs, how columns are sized and laid out, what background images or colors are used, layout designs,variations in display for different devices and screen sizes as well as a variety of other effects.
CSS is easy to learn and understand but it provides powerful control over the presentation of an HTML document. Most commonly, CSS is combined with the markup languages HTML or XHTML.
CSS is created and maintained through a group of people within the W3C called the CSS Working Group. The CSS Working Group creates documents called specifications. When a specification has been discussed and officially ratified by the W3C members, it becomes a recommendation.
These ratified specifications are called recommendations because the W3C has no control over the actual implementation of the language. Independent companies and organizations create that software.

•	JS: JavaScript is a lightweight, interpreted programming language. It is designed for creating network-centric applications. It is complimentary to and integrated with Java. JavaScript is very easy to implement because it is integrated with HTML. It is open and cross-platform. Javascript is the most popular programming language in the world and that makes it a programmer’s great choice. Once you learnt Javascript, it helps you developing great front-end as well as back-end softwares using different Javascript based frameworks like jQuery, Node.JS etc.
•	BOOTSTRAP: Twitter Bootstrap is the most popular front end framework in the recent time. It is sleek, intuitive, and powerful mobile first front-end framework for faster and easier web development. It uses HTML, CSS and Javascript. This tutorial will teach you the basics of Bootstrap Framework using which you can create web projects with ease. The tutorial is divided into sections such as Bootstrap Basic Structure, Bootstrap CSS, Bootstrap Layout Components and Bootstrap Plugins. Each of these sections contain related topics with simple and useful examples.
Back End:
•	PYTHON : Python is a very popular general-purpose interpreted, interactive, object-oriented, and high-level programming language. Python is dynamically-typed and garbage-collected programming language. It was created by Guido van Rossum during 1985- 1990. Like Perl, Python source code is also available under the GNU General Public License (GPL). Python is very high in demand and all the major companies are looking for great Python Programmers to develop websites, software components, and applications or to work with Data Science, AI, and ML technologies. When we are developing this tutorial in 2022, there is a high shortage of Python Programmers where as market demands more number of Python Programmers due to it's application in Machine Learning, Artificial Intelligence etc.
Prediction Models :
•	DECISIONTREE : Decision tree analysis is a predictive modelling tool that can be applied across many areas. Decision trees can be constructed by an algorithmic approach that can split the dataset in different ways based on different conditions. Decisions trees are the most powerful algorithms that falls under the category of supervised algorithms.
They can be used for both classification and regression tasks. The two main entities of a tree are decision nodes, where the data is split and leaves, where we got outcome.
The automatic production of decision rules for instance is referred to as rule induction or automatic rule induction. It can be creating decision rules in the implicit design of a decision tree are also frequently known as rule induction, but the terms tree induction or decision tree inductions are constantly chosen.
The basic algorithm for decision tree induction is a greedy algorithm. It is used to generate decision trees in a top-down recursive divide-and-conquer manner. The basic algorithm for learning decision trees, is a form of ID3, a famous decision tree induction algorithm.

•	NBCLASSIFIER : Decision tree analysis is a predictive modelling tool that can be applied across many areas. Decision trees can be constructed by an algorithmic approach that can split the dataset in different ways based on different conditions. Decisions trees are the most powerful algorithms that falls under the category of supervised algorithms.
They can be used for both classification and regression tasks. The two main entities of a tree are decision nodes, where the data is split and leaves, where we got outcome.
o	Naïve: It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.
o	Bayes: It is called Bayes because it depends on the principle of Bayes' Theorem.
•	PLANT_DISEASE_MODEL : A plant disease model is a mathematical description of the interaction between environmental, host, and pathogen variables that can result in disease. A model can be presented as a simple rule, an equation, a graph, or a table. The output of a model can be a numerical index of disease risk, predicted disease incidence or severity, and/or predicted inoculum development.
•	Plant disease models typically are developed in specific climates and regions around the world. Before usina a model not field tested or validated for a specific location, test the model for one or more seasons under local conditions to verify that it will work in this location. Models may contain assumptions about site specific conditions that might not apply for all areas. Input variables and/or other parameters, such as timing of model initiation, may need adjustment due to pathogen biology, host phenology, and variety in a specific area.
•	Disease model information was first assembled from published literature, as well as written documents supplied by the researchers, and then presented in a standard format. When several models are available for a disease, they are listed in reverse chronological order, by date of publication. When information is incomplete, the field is left blank, or termed "in progress" or "unspecified."
•	The fields of the database include:
Crop
•	A crop of economic importance to California agriculture.
Disease
•	A disease of economic importance in California.
Pathogen
•	The scientific name of the pathogen that causes the disease.
Model developer and citation
•	The citation(s) of the published model. When models have been modified by either the original researcher or another researcher, the most recent model is listed first. The original model also is listed separately from the modified model.
Weather station and sensor location
•	The location of weather monitoring equipment relative to the crop canopy. The sensors that monitor the environmental variables may be located within a crop canopy or may be part of a standardized reporting station at the edge of the field or other nearby location. To reproduce model results, it is important to place the sensors in the same location as they were in the research and validation work.
Input variables
•	The data used to run a disease model. Measured environmental variables are recorded by automated weather stations or other types of monitoring equipment. Variables typically monitored include temperature, precipitation, relative humidity, and leaf wetness. Leaf wetness is a very site-specific variable; therefore, the sensor must be placed in the appropriate place relative to the crop canopy. Forecast environmental variables are developed by weather services. Calculated environmental variables are measured variables that are transformed by mathematical calculations, such as degree-hours or dew points. Host variables include crop growth stage, cultivar, and other host factors. Pathogen variables include inoculum potential, maturity of spores, and other pathogen factors.
Model description
•	The mathematical relationship that describes the interaction between the environment, host, and pathogen variables, and disease. The model can be presented as an equation, a graph, a table, or a simple rule. The output of a model can be a numerical index of disease risk. For further information on the model, see the original model reference, listed under Model Developer and Citation.

•	RANDOMFOREST : Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.
As the name suggests, "Random Forest is a classifier that contains a number of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset." Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the majority votes of predictions, and it predicts the final output.
The greater number of trees in the forest leads to higher accuracy and prevents the problem of overfitting.
Since the random forest combines multiple trees to predict the class of the dataset, it is possible that some decision trees may predict the correct output, while others may not. But together, all the trees predict the correct output. Therefore, below are two assumptions for a better Random forest classifier:
There should be some actual values in the feature variable of the dataset so that the classifier can predict accurate results rather than a guessed result.
The predictions from each tree must have very low correlations.


•	XGBoost : XGBoost is an optimized distributed gradient boosting library designed for efficient and scalable training of machine learning models. It is an ensemble learning method that combines the predictions of multiple weak models to produce a stronger prediction. XGBoost stands for “Extreme Gradient Boosting” and it has become one of the most popular and widely used machine learning algorithms due to its ability to handle large datasets and its ability to achieve state-of-the-art performance in many machine learning tasks such as classification and regression.
One of the key features of XGBoost is its efficient handling of missing values, which allows it to handle real-world data with missing values without requiring significant pre-processing. Additionally, XGBoost has built-in support for parallel processing, making it possible to train models on large datasets in a reasonable amount of time.
XGBoost can be used in a variety of applications, including Kaggle competitions, recommendation systems, and click-through rate prediction, among others. It is also highly customizable and allows for fine-tuning of various model parameters to optimize performance.
XgBoost stands for Extreme Gradient Boosting, which was proposed by the researchers at the University of Washington. It is a library written in C++ which optimizes the training for Gradient Boosting.

	
	
